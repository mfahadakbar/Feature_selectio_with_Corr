{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FE_with_Corr_Git.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfahadakbar/Feature_selection_with_Corr/blob/master/FE_with_Corr_Git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUhKfWrW48F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# made by Fahad Akbar , you can contact me at fahadakbarr@gmail.com\n",
        "# only suitable for supervised ML problems (regression and 2 calss classification)\n",
        "def c_f(input_data,threshold,target_variable):\n",
        "\n",
        "  global data1\n",
        "  data1 = input_data.copy()\n",
        "  # make an correlation db with abs correlation db\n",
        "  corr_matrix = abs(data1.corr())\n",
        "\n",
        "  # for every diagonal value, make it Nan\n",
        "  corr_matrix.values[tuple([np.arange(corr_matrix.shape[0])]*2)] = np.NaN\n",
        "\n",
        "  # Now Calculate the average correlation of every feature with other, and get a pandas data frame\n",
        "  avg_cor = pd.DataFrame(corr_matrix.mean())\n",
        "  avg_cor['feature']= avg_cor.index\n",
        "  avg_cor.reset_index(drop=True, inplace=True)\n",
        "  avg_cor.columns =  ['avg_cor','features']\n",
        "  \n",
        "  # Calculate the correlation with the target\n",
        "  targ_cor = pd.DataFrame(corr_matrix[target_variable].dropna())\n",
        "  targ_cor['feature']= targ_cor.index\n",
        "  targ_cor.reset_index(drop=True, inplace=True)\n",
        "  targ_cor.columns =  ['target_variable','features']\n",
        "\n",
        "  # Now, add a column for variable name and drop index\n",
        "  corr_matrix['column'] = corr_matrix.index\n",
        "  corr_matrix.reset_index(drop=True,inplace=True)\n",
        "\n",
        "  # now we need to melt it , so that we can corelation pair wise , with two columns \n",
        "  cols =corr_matrix.column\n",
        "  melt = corr_matrix.melt(id_vars= ['column'],value_vars=cols).sort_values(by='value',ascending=False).dropna()\n",
        "\n",
        "  # now bring in the avg correlation for first of the pair\n",
        "  merge = pd.merge(melt,avg_cor,left_on='column',right_on='features').drop('features',axis=1)\n",
        "\n",
        "  # now bring in the avg correlation for second of the pair\n",
        "  merge = pd.merge(merge,avg_cor,left_on='variable',right_on='features').drop('features',axis=1)\n",
        "  \n",
        "  # now bring in the target correlation for first of the pair\n",
        "  merge = pd.merge(merge,targ_cor,left_on='column',right_on='features').drop('features',axis=1)\n",
        "\n",
        "  # now bring in the avg correlation for second of the pair\n",
        "  merge = pd.merge(merge,targ_cor,left_on='variable',right_on='features').drop('features',axis=1)\n",
        "\n",
        "  # sort and save\n",
        "  merge = merge.sort_values(by='value',ascending=False)\n",
        "\n",
        "  # we need to now eleminate all the pairs that are actually duplicate e.g cor(x,y) = cor(y,x) , they are the same , we need to find these and drop them\n",
        "  merge['all_columns'] = merge['column'] + merge['variable']\n",
        "\n",
        "  # this puts all the coresponding pairs of features togather , so that we can only take one, since they are just the duplicates\n",
        "  merge['all_columns'] = [sorted(i) for i in merge['all_columns'] ]\n",
        "\n",
        "  # now sort by new column\n",
        "  merge = merge.sort_values(by='all_columns')\n",
        "\n",
        "  # take every second colums\n",
        "  merge = merge.iloc[::2, :]\n",
        "\n",
        "  # make a ranking column to eliminate features\n",
        "  merge['rank_x'] = round((merge['avg_cor_y']- merge['avg_cor_x']) + (merge['target_variable_x'] - merge['target_variable_y']),6) # round it to 6 digits\n",
        "\n",
        "  ## Now there will be rows where the rank will be exactly zero, these is where the value (corelartion between features) is exactly one ( like price and price^2)\n",
        "  ## so in that case , we can simply pick one of the variable\n",
        "  # but since , features can be in either column, we will drop one column (say 'column') , only if the feature is not in the second column (in variable column)\n",
        "  # both equations below will return the list of columns to drop from here \n",
        "  # this is how it goes\n",
        "\n",
        "  ## For the portion where correlation is exactly one !\n",
        "  one = merge[merge['rank_x']==0]\n",
        "\n",
        "  #[i for i in pd.unique(small['column']) if i not in pd.unique(small['variable'])]\n",
        "  to_drop =(list(set(one['column'])-set(one['variable'])))\n",
        "\n",
        "  ## now we are to treat where rank is not Zero and Value (corelation) is greater than a specific threshold\n",
        "  non_zero = merge[(merge['rank_x']!= 0.0) & (merge['value'] >= threshold)]\n",
        "\n",
        "  # pick the column to delete\n",
        "  non_zero_list = list(np.where(non_zero['rank_x'] < 0 , non_zero['column'], non_zero['variable']))\n",
        "\n",
        "  # add two list\n",
        "  to_drop = to_drop + non_zero_list\n",
        "\n",
        "  #make sure that target column is not a part of the list\n",
        "  try:\n",
        "    to_drop.remove(target_variable)\n",
        "  except:\n",
        "    to_drop\n",
        "\n",
        "  #Final Step, drop the columns from data\n",
        "  data1.drop(to_drop,axis=1,inplace=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}